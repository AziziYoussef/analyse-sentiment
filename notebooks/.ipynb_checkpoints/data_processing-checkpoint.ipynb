{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  Saint-Nazaire se rêve en capitale des #énergie...     =\n",
      "1  4eme Conférence internationale sur le changeme...     =\n",
      "2  Rencontres #windustry 2014 Sascha Wiesner décr...     =\n",
      "3  #Photos :Dans l’Ouest américain,les stigmates ...     -\n",
      "4  Parc #éolien: entente conclut entre Port-Carti...     +\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "train_file = '../data/train.txt'\n",
    "dev_file = '../data/dev.txt'\n",
    "\n",
    "# Read the files into DataFrames\n",
    "train_df = pd.read_csv(train_file, sep='\\t', header=None, names=['text', 'label'])\n",
    "dev_df = pd.read_csv(dev_file, sep='\\t', header=None, names=['text', 'label'])\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6925</td>\n",
       "      <td>6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6921</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>J'aime une vidéo @YouTube : \"Fabriquer une éol...</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "count                                                6925  6920\n",
       "unique                                               6921     3\n",
       "top     J'aime une vidéo @YouTube : \"Fabriquer une éol...     =\n",
       "freq                                                    2  3102"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>688</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>688</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Les Éd. De #logiciel, un écosystème plein de v...</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "count                                                 688   688\n",
       "unique                                                688     3\n",
       "top     Les Éd. De #logiciel, un écosystème plein de v...     =\n",
       "freq                                                    1   323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6925, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\", disable=[\"tagger\", \"parser\", \"ner\"])  # Disable unnecessary components for speed\n",
    "fr_stopwords = set(fr_stopwords)  # Cache stopwords for faster lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_french_text(text):\n",
    "    # Tokenize and lemmatize\n",
    "    doc = nlp(text)\n",
    "    # Remove stopwords and punctuation, lemmatize, and lowercase tokens\n",
    "    tokens = [token.lemma_.lower() for token in doc if token.text.lower() not in fr_stopwords and not token.is_punct]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokens'] = train_df['text'].apply(preprocess_french_text)\n",
    "dev_df['tokens'] = dev_df['text'].apply(preprocess_french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint-Nazaire se rêve en capitale des #énergie...</td>\n",
       "      <td>=</td>\n",
       "      <td>[saint-nazaire, rêve, capitale, énergie, marin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4eme Conférence internationale sur le changeme...</td>\n",
       "      <td>=</td>\n",
       "      <td>[4eme, conférence, international, changement, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rencontres #windustry 2014 Sascha Wiesner décr...</td>\n",
       "      <td>=</td>\n",
       "      <td>[rencontres, windustry, 2014, sascha, wiesner,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Photos :Dans l’Ouest américain,les stigmates ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[photo, ouest, américain, stigmate, sécheresse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parc #éolien: entente conclut entre Port-Carti...</td>\n",
       "      <td>+</td>\n",
       "      <td>[parc, éolien, entente, conclure, port-cartier...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  Saint-Nazaire se rêve en capitale des #énergie...     =   \n",
       "1  4eme Conférence internationale sur le changeme...     =   \n",
       "2  Rencontres #windustry 2014 Sascha Wiesner décr...     =   \n",
       "3  #Photos :Dans l’Ouest américain,les stigmates ...     -   \n",
       "4  Parc #éolien: entente conclut entre Port-Carti...     +   \n",
       "\n",
       "                                              tokens  \n",
       "0  [saint-nazaire, rêve, capitale, énergie, marin...  \n",
       "1  [4eme, conférence, international, changement, ...  \n",
       "2  [rencontres, windustry, 2014, sascha, wiesner,...  \n",
       "3  [photo, ouest, américain, stigmate, sécheresse...  \n",
       "4  [parc, éolien, entente, conclure, port-cartier...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes dans la colonne 'label': 5\n",
      "Indices des lignes avec des labels manquants: [301, 2553, 2554, 2555, 2662]\n",
      "Dimensions d'origine: (6925, 3), Nouvelles dimensions: (6920, 3)\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "print(\"Nombre de valeurs manquantes dans la colonne 'label':\", train_df['label'].isna().sum())\n",
    "print(\"Indices des lignes avec des labels manquants:\", train_df.index[train_df['label'].isna()].tolist())\n",
    "\n",
    "# Supprimer les lignes avec des labels manquants\n",
    "train_df_clean = train_df.dropna(subset=['label'])\n",
    "print(f\"Dimensions d'origine: {train_df.shape}, Nouvelles dimensions: {train_df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser les données nettoyées pour créer X_train et y_train\n",
    "X_train = train_df_clean['tokens'].apply(lambda x: ' '.join(x))  # Join tokens into a single string\n",
    "X_dev = dev_df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Labels\n",
    "y_train = train_df_clean['label']\n",
    "y_dev = dev_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions d'origine: (6925, 3), Nouvelles dimensions: (6920, 3)\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les lignes avec des labels manquants\n",
    "train_df_clean = train_df.dropna(subset=['label'])\n",
    "print(f\"Dimensions d'origine: {train_df.shape}, Nouvelles dimensions: {train_df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data (using clean data)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the development data\n",
    "X_dev_tfidf = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision: 66.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.65      0.55      0.60       208\n",
      "           -       0.70      0.52      0.59       157\n",
      "           =       0.66      0.81      0.72       323\n",
      "\n",
      "    accuracy                           0.66       688\n",
      "   macro avg       0.67      0.62      0.64       688\n",
      "weighted avg       0.66      0.66      0.66       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model with increased max_iter\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model with clean data\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Évaluer le modèle\n",
    "y_pred = model.predict(X_dev_tfidf)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(f\"Précision: {accuracy_score(y_dev, y_pred)*100:.2f}%\")\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

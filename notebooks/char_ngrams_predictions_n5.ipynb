# %% [markdown]
# # Classificateur de textes par apprentissage automatique
# 
# Ce notebook implémente un pipeline complet de classification de textes avec différents modèles (SVM, Naïve Bayes, etc.).

# %% [markdown]
# ## 1. Configuration initiale

# %%
%%capture
!pip install scikit-learn pandas matplotlib

# %%
import sys
import numpy as np
import pandas as pd
import re
import string
import warnings
import pickle
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

# Suppression des avertissements
warnings.filterwarnings("ignore")

# %% [markdown]
# ## 2. Fonctions de prétraitement

# %%
def preprocess_text(text):
    """Prétraite un texte pour la classification."""
    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def load_data(file_path):
    """Charge les données depuis un fichier texte."""
    data = []
    labels = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split("\t")
            if len(parts) >= 2:
                text = parts[0]
                label = parts[1] if parts[1] != "??" else None
                data.append(text)
                labels.append(label)
    
    return pd.DataFrame({'text': data, 'label': labels})

# %% [markdown]
# ## 3. Entraînement du modèle

# %%
def train_model(model_type='svm'):
    """Entraîne et évalue un modèle de classification."""
    # Chargement des données
    train_df = load_data('./data/train.txt')
    dev_df = load_data('./data/dev.txt')
    
    # Prétraitement
    train_df['processed_text'] = train_df['text'].apply(preprocess_text)
    dev_df['processed_text'] = dev_df['text'].apply(preprocess_text)
    
    # Encodage des labels
    label_encoder = LabelEncoder()
    y_train = label_encoder.fit_transform(train_df['label'])
    y_dev = label_encoder.transform(dev_df['label'])
    
    # Configuration du pipeline
    if model_type == 'nb':
        pipeline = Pipeline([
            ('vectorizer', TfidfVectorizer(min_df=2, max_df=0.95, max_features=10000)),
            ('classifier', MultinomialNB())
        ])
    elif model_type == 'char':
        pipeline = Pipeline([
            ('vectorizer', TfidfVectorizer(analyzer='char', ngram_range=(2, 4),
                           min_df=2, max_df=0.95, max_features=10000),
            ('classifier', LinearSVC(random_state=42))
        ])
    else:
        pipeline = Pipeline([
            ('vectorizer', TfidfVectorizer(min_df=2, max_df=0.95, max_features=10000)),
            ('classifier', LinearSVC(random_state=42))
        ])
    
    # Entraînement
    pipeline.fit(train_df['processed_text'], y_train)
    
    # Évaluation
    y_pred = pipeline.predict(dev_df['processed_text'])
    accuracy = np.mean(y_pred == y_dev)
    print(f"Exactitude sur dev: {accuracy:.4f}")
    
    # Sauvegarde
    with open(f"model_{model_type}.pkl", 'wb') as f:
        pickle.dump(pipeline, f)
    
    with open(f"label_encoder_{model_type}.pkl", 'wb') as f:
        pickle.dump(label_encoder, f)
    
    return pipeline, label_encoder

# %% [markdown]
# ## 4. Prédictions

# %%
def predict(input_file, model_type='svm'):
    """Effectue des prédictions sur de nouvelles données."""
    # Chargement du modèle
    try:
        with open(f"model_{model_type}.pkl", 'rb') as f:
            pipeline = pickle.load(f)
        with open(f"label_encoder_{model_type}.pkl", 'rb') as f:
            label_encoder = pickle.load(f)
    except FileNotFoundError:
        print("Entraînement du modèle...")
        pipeline, label_encoder = train_model(model_type)
    
    # Lecture des données
    lines = [line.strip().split("\t")[0] for line in input_file if line.strip()]
    
    # Prédiction
    processed_texts = [preprocess_text(text) for text in lines]
    predictions = label_encoder.inverse_transform(pipeline.predict(processed_texts))
    
    # Affichage des résultats
    for text, pred in zip(lines, predictions):
        print(f"{text}\t{pred}")

# %% [markdown]
# ## 5. Utilisation interactive

# %%
# Paramètres à modifier
MODEL_TYPE = 'svm'  # 'svm', 'nb' ou 'char'
MODE = 'train'      # 'train' ou 'predict'
INPUT_FILE = 'dev.txt'  # Fichier à utiliser en mode prédiction

# %%
if MODE == 'train':
    pipeline, label_encoder = train_model(MODEL_TYPE)
else:
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        predict(f, MODEL_TYPE)

# %% [markdown]
# ## 6. Visualisation des résultats (optionnel)

# %%
# Exemple de visualisation des features importantes
if MODE == 'train' and MODEL_TYPE == 'svm':
    feature_names = pipeline.named_steps['vectorizer'].get_feature_names_out()
    coefs = pipeline.named_steps['classifier'].coef_
    
    top_features = np.argsort(coefs[0])[-20:]
    print("\nFeatures les plus importantes:")
    print([feature_names[i] for i in top_features])